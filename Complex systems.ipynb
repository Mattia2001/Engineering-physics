{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "iraqi-straight",
   "metadata": {},
   "source": [
    "# Law of large numbers\n",
    "\n",
    "$$\\lim_{N\\rightarrow\\infty}P(|y_N - \\mu| > \\epsilon) \\rightarrow 0 \\hspace{1cm}\\forall \\epsilon >0 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "matched-traveler",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrative-stranger",
   "metadata": {},
   "source": [
    "In first place we need a vector containing the results of $N$ experiments. This is done by using the \"random.randint\" command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amber-municipality",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 600 # assume to roll a dice N times\n",
    "results = np.array([random.randint(1,6) for i in range(N)]) # turn the list into np array for plotting convenience\n",
    "#print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "measured-adobe",
   "metadata": {},
   "source": [
    "Now we need a function which computes the average from time to time, stores the results into a vector and then plots the average profile. The expected value of the dice rolling is 3.5, thus we expect the average estimator $y_N$ to approach 3.5 as $N$ grows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fantastic-aircraft",
   "metadata": {},
   "outputs": [],
   "source": [
    "def av_estimator(x):\n",
    "    av_values = []\n",
    "    for i,j in enumerate(x): # i=index, j=element\n",
    "        av_value = np.sum(x[:i])/(i+1) # calculate the average at each step\n",
    "        av_values.append(av_value) # create a vector which contains all the averages\n",
    "    return np.array(av_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "synthetic-walker",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(av_estimator(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "partial-innocent",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = np.linspace(1, N, N)\n",
    "plt.plot(trials,av_estimator(results), 'o')\n",
    "plt.axhline(y = 3.5, color = 'r', linestyle = '-') # expected value\n",
    "plt.xlabel('Experiment')\n",
    "plt.ylabel('Average')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "middle-outside",
   "metadata": {},
   "source": [
    "# Random walk\n",
    "\n",
    "In first place we generate a list of $N$ experiments containing $+1$ or $-1$ (each step has length |1|). This is done with \"random.randint\" command. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "close-biodiversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-taxation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function produces the different walks and also the grid to perform the plotting\n",
    "\n",
    "def get_walk(N_steps):\n",
    "    step_types = [-1,1] # here you can modify the length and direction of steps\n",
    "    experiments =  np.array(list(range(0, N_steps, 1))) #produce the grid for plotting\n",
    "    steps = np.array([random.choice(step_types) for j in range(N_steps)])\n",
    "    #print(steps)\n",
    "    return steps, experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bottom-ranking",
   "metadata": {},
   "source": [
    "Then we need a function which is evaluating the distance from the origin from time to time (i.e. from experiment to experiment).\n",
    "This function makes use of the list produced at previous step and also return a list containing the position of the walker at each experiment. Element \"i\" of this list is simply equal to the sum of all the elements of list \"experiments\" with index lower than \"i\". Then the positions achieved at each step are displayed on a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "remarkable-doubt",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distances(steps):\n",
    "    distances = []\n",
    "    for i,j in enumerate(steps):\n",
    "        distance = np.sum(steps[:i]) # sum all the elements coming before (I guess that there is a less copmutationally-expensive way)\n",
    "        distances.append(distance)\n",
    "    return np.array(distances)\n",
    "\n",
    "#print(get_distances(steps))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unsigned-eclipse",
   "metadata": {},
   "source": [
    "Let us verify the law of large numbers. The average should converge to the expected value of the random walk (which is zero) and the probability of observing fluctuations from the expected value should vanish with the increasing number of experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baking-accuracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_walkers = 1\n",
    "N_steps = 500\n",
    "\n",
    "for i in range(N_walkers):\n",
    "    steps, experiments = get_walk(N_steps) # 500 steps\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(15,4))\n",
    "    plt.plot(experiments, get_distances(steps), '-')\n",
    "    plt.axhline(y = 0, color = 'r', linestyle = '-') # expected value\n",
    "    plt.xlabel('Experiment')\n",
    "    plt.ylabel('Walker position')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    # here we veirfy the law of large numbers\n",
    "    fig2, ax2 = plt.subplots(1, 1, figsize=(15,4))\n",
    "    plt.plot(experiments, av_estimator(steps), 'o')\n",
    "    plt.axhline(y = 0, color = 'r', linestyle = '-') # expected value\n",
    "    plt.xlabel('Experiment')\n",
    "    plt.ylabel('Average')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automotive-reading",
   "metadata": {},
   "source": [
    "We now try to make an animation of the random walk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "stock-catalyst",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.animation import PillowWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "systematic-holly",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we make the animation of three walkers\n",
    "\n",
    "N_steps = 1000\n",
    "\n",
    "metadata = dict(title = 'Random walk')\n",
    "writer = PillowWriter(fps = 10, metadata = metadata)\n",
    "\n",
    "fig = plt.figure()\n",
    "l1, = plt.plot([], [], 'b-', label=\"Walker 1\")\n",
    "l2, = plt.plot([], [], 'r-', label=\"Walker 2\")\n",
    "l3, = plt.plot([], [], 'g-', label=\"Walker 3\")\n",
    "\n",
    "plt.axhline(y = 0, color = 'k', linestyle = '--') # expected value\n",
    "plt.grid(True)\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Position')\n",
    "plt.legend(loc='upper right', ncol=3)\n",
    "plt.title('Random walk')\n",
    "\n",
    "xvals1 = []\n",
    "yvals1 = []\n",
    "yvals2 = []\n",
    "yvals3 = []\n",
    "\n",
    "with writer.saving(fig, \"Random_Walk.gif\", 100):\n",
    "    steps1, experiments1 = get_walk(N_steps)\n",
    "    steps2, experiments2 = get_walk(N_steps)\n",
    "    steps3, experiments3 = get_walk(N_steps)\n",
    "    distances1 = list(get_distances(steps1))\n",
    "    distances2 = list(get_distances(steps2))\n",
    "    distances3 = list(get_distances(steps3))\n",
    "    plt.xlim(0, 1000)\n",
    "    # in order to set max and min on the vertical exis we have to check all the trajectories and select absolute max and min\n",
    "    max_min_distances = [max(distances1), max(distances2), max(distances3), min(distances1), min(distances2), min(distances3)]\n",
    "    plt.ylim(min(max_min_distances)-10, max(max_min_distances)+10) \n",
    "    for j, experiment in  enumerate(list(experiments1)):\n",
    "        xvals1.append(experiment)\n",
    "        yvals1.append(distances1[j])\n",
    "        yvals2.append(distances2[j])\n",
    "        yvals3.append(distances3[j])\n",
    "        \n",
    "        l1.set_data(xvals1, yvals1)\n",
    "        l2.set_data(xvals1, yvals2)\n",
    "        l3.set_data(xvals1, yvals3)\n",
    "        \n",
    "        writer.grab_frame()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "characteristic-future",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify large numbers law (just for the first walker)\n",
    "\n",
    "metadata = dict(title = 'Law of large numbers')\n",
    "writer = PillowWriter(fps = 10, metadata = metadata)\n",
    "\n",
    "fig = plt.figure()\n",
    "l, = plt.plot([], [], 'b-')\n",
    "plt.xlim(0, 1000)\n",
    "plt.ylim(-1, 1)\n",
    "plt.axhline(y = 0, color = 'r', linestyle = '-') # expected value\n",
    "plt.grid(True)\n",
    "plt.xlabel('Experiment')\n",
    "plt.ylabel('Average')\n",
    "plt.title('Law of large numbers')\n",
    "\n",
    "xvals = []\n",
    "yvals = []\n",
    "\n",
    "with writer.saving(fig, \"Large_numbers.gif\", 100):\n",
    "    averages = list(av_estimator(steps1))\n",
    "    for j, experiment in  enumerate(list(experiments1)):\n",
    "        xvals.append(experiment)\n",
    "        yvals.append(averages[j])\n",
    "        \n",
    "        l.set_data(xvals, yvals)\n",
    "        \n",
    "        writer.grab_frame()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "employed-sustainability",
   "metadata": {},
   "source": [
    "# Central limit theorem\n",
    "\n",
    "$$P_{N}(x) \\xrightarrow[N\\rightarrow\\infty]{} \\frac{1}{\\sqrt{2\\pi N^2}} e^{-\\frac{x^2}{2N^2}}$$\n",
    "\n",
    "Now we want to visualize the central limit theorem. In order to do this we require a huge number of walkers. We need a function which creates a list of lists. Each of these lists contains one random walk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "going-sword",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_of_walks(N_walkers, N_steps):\n",
    "    walks = []\n",
    "    for i in range(N_walkers):\n",
    "        steps, experiments = get_walk(N_steps) \n",
    "        walk = get_distances(steps)\n",
    "        walks.append(walk)\n",
    "    \n",
    "    return np.array(experiments), np.array(walks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blocked-account",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we plot all the walkers, this is optional, since we are using a huge number of walkers \n",
    "# (otherwise we cannot verify central limit theorem) it is preferable to comment this section\n",
    "'''\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15,4)) \n",
    "plt.axhline(y = 0, color = 'r', linestyle = '-') # expected value\n",
    "plt.xlabel('Experiment')\n",
    "plt.ylabel('Walker position')\n",
    "plt.grid(True)\n",
    "\n",
    "experiments, walks = list_of_walks(N_walkers, N_steps)\n",
    "for i in walks:\n",
    "    plt.plot(experiments, i, '-')\n",
    "plt.show()\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apparent-start",
   "metadata": {},
   "source": [
    "Now we want to verify that the average position of the walkers is described by a Gaussian. Thus we have to take the last position of each walker and then check whether the distribution of these positions respects a Gaussian distribution with variance equal to the number of steps and zero mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unusual-plenty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function receives a list of random walks and creates a list containing the last position of each walk\n",
    "# Then, this list will be used to check whether, in the limit of a large number of walkers and for a sufficiently large number\n",
    "# of steps, the distribution of the walks resembles the Gaussian described by the central limit theorem.\n",
    "\n",
    "def get_last_points(walks):\n",
    "    last_points = []\n",
    "    for walk in walks:\n",
    "        last_points.append(walk[:-1])\n",
    "    return np.array(last_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjusted-meditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_walkers = 1000\n",
    "N_steps = 1000\n",
    "\n",
    "experiments, walks = list_of_walks(N_walkers, N_steps)\n",
    "last_points = get_last_points(walks)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.hist(last_points, bins=30, density=True, histtype='barstacked')\n",
    "plt.show()\n",
    "\n",
    "print(f\"The mean of the random walks is: {np.mean(last_points)}\")\n",
    "print(f\"The variance of the random walks is: {2*np.var(last_points)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ancient-settlement",
   "metadata": {},
   "source": [
    "We notice that the mean is always next to zero and the variance is near to the number of steps. Thus the central limit theorem for the random walk is verified. There are two facts that have to be stated. The first one is that the program fails for a number of walkers in range 3000. Then, the actual formulation of the central limit theorem requires a number of walkers which is even larger (about $10^{23}$) than the one which we are able to handle on the computer. Thus, if we were able to reach a higher number of walkers, we could get an average which is even nearer to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pretty-awareness",
   "metadata": {},
   "source": [
    "# Visualizing the diffusion \n",
    "\n",
    "Here we make an animation which allows us to visualize the process of diffusion taking place. We know both the diffusion equation (in absence of external forces for now) and its solution:\n",
    "\n",
    "$$\\frac{\\partial \\rho(x,t)}{\\partial t} = D\\frac{\\partial^2 \\rho(x,t)}{\\partial x^2} \\hspace{1cm} \\rho(x,t) = \\frac{1}{\\sqrt{2\\pi (\\sigma^2 + 2Dt)}}e^{-\\frac{x^2}{2(\\sigma^2 + 2Dt)}} \\hspace{1cm} D = k_B T\\mu$$\n",
    "\n",
    "$\\sigma^2$ is the variance of the density at time $t=0$ i.e. in the instant before the diffusion process takes place. Thus, if we hypothesize that the density is highly localized at the initial time instant, we can set this value to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "selected-bacon",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import pi\n",
    "from matplotlib import animation\n",
    "from matplotlib.animation import PillowWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bigger-softball",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This fucntion produces the Gaussian representing the density\n",
    "\n",
    "def density(x, y, t, sigma_in, D):\n",
    "    norm = 1/np.sqrt(2*pi*(sigma_in**2 + 2*D*t))\n",
    "    exponential = np.exp(-(x**2 + y**2) / (2*(sigma_in**2 + 2*D*t)))\n",
    "    return norm*exponential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polished-province",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = dict(title = 'Law of large numbers')\n",
    "writer = PillowWriter(fps = 10, metadata = metadata)\n",
    "\n",
    "x = np.linspace(-5,5,100)\n",
    "\n",
    "fig = plt.figure()\n",
    "l, = plt.plot([], [], 'b-', label='D= 1')\n",
    "l2, = plt.plot([], [], 'r-', label = 'D=0.1')\n",
    "l3, = plt.plot([], [], 'g-', label = 'D=2')\n",
    "plt.xlim(-5, 5)\n",
    "plt.ylim(-0.1, 1.5)\n",
    "plt.grid(True)\n",
    "plt.legend(loc='upper right')\n",
    "#time_text = ax.text(0.65, 0.95, '', fontsize=15, transform=ax.transAxes, bbox=dict(facecolor='white', edgecolor='black'))\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Diffusion in 1 dimension')\n",
    "\n",
    "def animate(i):\n",
    "    l.set_data(x, density(x, 0, 1/50*i , 0.01, 1))\n",
    "    l2.set_data(x, density(x, 0, 1/50*i , 0.01, 0.1))\n",
    "    l3.set_data(x, density(x, 0, 1/50*i , 0.01, 2))\n",
    "    #time_text.set_text('t={:.2f}'.format(i/50))\n",
    "    \n",
    "ani = animation.FuncAnimation(fig, animate, frames=240, interval=50)\n",
    "ani.save(r'C:\\Users\\matti\\Downloads/Diffusion_1D.gif', writer='pillow', fps=100, dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "placed-conversation",
   "metadata": {},
   "source": [
    "Next step is to produce another animation but in 3D. Thus we require 2 space dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aging-tackle",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-4,4, 100)\n",
    "y = np.linspace(-4,4, 100)\n",
    "xv, yv = np.meshgrid(x, y)\n",
    "\n",
    "plt.contourf(xv, yv, density(xv, yv, 0.1, 0.1, 1), levels=30, cmap='plasma')  #f = filled in, add vmin or vmax to turn all the points below or above a certain value of the same colour\n",
    "plt.colorbar(label='Density')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(subplot_kw={'projection':'3d'}, figsize=(12,8))\n",
    "ax.plot_surface(xv, yv, density(xv, yv, 0.1, 0.1, 1), cmap='plasma')\n",
    "#ax.plot_surface(xv, yv, density(xv, yv, 5, 0.1, 1), cmap='plasma')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informal-flash",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(111,projection='3d')\n",
    "\n",
    "\n",
    "def animate(n):\n",
    "    ax.cla()\n",
    "\n",
    "    ax.plot_surface(xv, yv, density(xv, yv, 1/100*n, 0.1, 0.1))\n",
    "    ax.set_zlim(-1, 3)\n",
    "\n",
    "    return fig,\n",
    "\n",
    "\n",
    "ani = animation.FuncAnimation(fig, animate, frames=500, interval=5)\n",
    "ani.save(r'C:\\Users\\matti\\Downloads/Diffusion_3D.gif', writer='pillow', fps=10, dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organizational-output",
   "metadata": {},
   "source": [
    "# Markov chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historic-triple",
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_dict = {'Avezzano': [0.5, 0.15, 0.25, 0.1], \n",
    "              'Borgo Via Nuova': [0.3, 0.4, 0.2, 0.1], \n",
    "              'Borgo Ottomila': [0.2, 0.6, 0.1, 0.1],\n",
    "              'Cerchio': [0.2, 0.15, 0.5, 0.15]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innocent-start",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turn the dictionary into a np array\n",
    "transition_matrix = np.array([transition_dict['Avezzano'], transition_dict['Borgo Via Nuova'], transition_dict['Borgo Ottomila'], transition_dict['Cerchio']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "activated-couple",
   "metadata": {},
   "source": [
    "We would like to see how thew Markov chain approaches equilibrium. This fact is ensured by the ergodic theorem. Then, by Perron-Frobenius theorem, we can assert that the equilibrium state is unique and is achieved for whatever initial condition.\n",
    "\n",
    "$$\\vec{\\pi}^{eq} = \\lim_{t\\rightarrow\\infty} \\vec{\\pi}^{0}P^t$$\n",
    "\n",
    "A first away of finding the equilibrium distribution consists in simply applying the formula above. Thus we need a function which is multiplying the transition matrix by itself a specified number of times until convergence is observed. Then, the equilibrium matrix (which is expected to have equal rows with non-zero elements), is multiplied by the initial condition vector. This method is the most brutal and unconvenient one from the computational point of view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "straight-france",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate(transition_matrix, max_iter):\n",
    "    threshold = 10**-8\n",
    "    old_matrix = transition_matrix\n",
    "    \n",
    "    iteration = 0\n",
    "    while iteration < max_iter:\n",
    "        new_matrix = old_matrix @ transition_matrix\n",
    "        \n",
    "        # The relative error check is made only on one element of the matrix, I guess that this feature can be improved\n",
    "        rel_err = abs(old_matrix[1,1] - new_matrix[1,1]) / old_matrix[1,1]\n",
    "        \n",
    "        if rel_err > threshold:\n",
    "            old_matrix = new_matrix\n",
    "            iteration +=1\n",
    "        else:\n",
    "            print(f\"Convergence achieved at iteration number: {iteration}.\")\n",
    "            return new_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superior-sally",
   "metadata": {},
   "outputs": [],
   "source": [
    "equilibrium_matrix = iterate(transition_matrix, 500)\n",
    "print(equilibrium_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficult-bacon",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi0 = np.array([1, 0, 0, 0]) #i.e. we are in Avezzano at time t=0\n",
    "eq_distribution = pi0 @ equilibrium_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inside-yellow",
   "metadata": {},
   "source": [
    "Th best way to find the equilibrium distribution is to apply Perron-Frobenius theorem, thus we have to solve the following eigevvalue equation:\n",
    "\n",
    "$$\\vec{\\pi}^{eq} = \\vec{\\pi}^{eq} P$$\n",
    "\n",
    "The equilibrium vector $\\vec{\\pi}^{eq}$ is the (only) eigenvector with associated eigenvalue equal to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenging-vegetarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dietary-program",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalues, eigenvectors = scipy.linalg.eig(transition_matrix, right = False, left = True)\n",
    "\n",
    "pi = eigenvectors[:,0] # select the eigenvalue associated to eigenvalue 1\n",
    "pi_normalized = [(x/np.sum(pi)).real for x in pi]\n",
    "print(pi_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cutting-tuning",
   "metadata": {},
   "source": [
    "# 1-D Ising model\n",
    "\n",
    "Let us study the 1-dimensional Ising model. In first place we need a function which produces an array of pins $s_i = \\pm 1$. The  arguments to be passed to this function are the number of spins and the number of up and down spins, if we want to create some specific configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "arctic-gazette",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desperate-classification",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spin_array(N_spins, N_up, N_down):\n",
    "    list_of_spin_down = [-1 for i in range(N_down)]\n",
    "    list_of_spin_up = [1 for i in range(N_up)]\n",
    "    spin_array = sample(list_of_spin_down + list_of_spin_up, len(list_of_spin_down + list_of_spin_up))\n",
    "    return np.array(spin_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "american-webmaster",
   "metadata": {},
   "source": [
    "Now we need a function evaluating the energy of our spin array. The Hamiltonian for the 1-D Ising model in presence of an external magnetic field $h$ is:\n",
    "\n",
    "$$H = -J\\sum_{i=0}^{N-1} s_i s_{i+1} - h\\sum_{i=0}^{N-1} s_i $$\n",
    "\n",
    "Let us also impose the periodic boundary conditions: $s_{N+1} = s_0$. This is required because, as long as we are considering a very small number of spins (i.e. we are not in the thermodynamical limit), this further contribution could be relevant. We define a function that computes the two different sums and combines them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-peace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_array_energy(spin_array, J, h):\n",
    "    \n",
    "    periodic_boundary = spin_array[0]*spin_array[-1]\n",
    "    H1 = 0\n",
    "    for i in range(len(spin_array)-1): # all spin-spin interactions except the boundary one\n",
    "        H1 = H1 + spin_array[i]*spin_array[i+1]\n",
    "    H1 = H1 + periodic_boundary\n",
    "        \n",
    "    H2 = np.sum(spin_array)\n",
    "    \n",
    "    return -J*H1 + (-h*H2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upper-satellite",
   "metadata": {},
   "outputs": [],
   "source": [
    "def magnetization_per_spin(spin_array):\n",
    "    m = np.mean(spin_array)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "above-prague",
   "metadata": {},
   "source": [
    "It is now time to study the approach to equilibrium i.e. to find the equilibrium configuration, starting from a random one, in presence of a certain temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "looking-companion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metropolis_monte_carlo(spin_array, T, max_iter, J, h):\n",
    "    all_configurations = [] # list with all Monte-Carlo configurations, needed for animation\n",
    "    all_configurations.append(spin_array)\n",
    "    \n",
    "    all_magnetizations = [] # list with all magnetizations, needed for animation\n",
    "    all_magnetizations.append(magnetization_per_spin(spin_array))\n",
    "    \n",
    "    # Here we start with Monte-Carlo method\n",
    "    \n",
    "    current_spin_array = spin_array\n",
    "    current_energy = get_array_energy(current_spin_array, J, h)\n",
    "    current_magnetization = magnetization_per_spin(spin_array)\n",
    "    \n",
    "    r = np.random.random() # sort a float in range 0,1\n",
    "    \n",
    "    # flip one random spin in the lattice and evaluate the new energy\n",
    "    k_B = 1\n",
    "    iteration = 0\n",
    "    while iteration < (max_iter-1):\n",
    "        \n",
    "         \n",
    "        flipping_loc = random.randint(0, len(current_spin_array)-1)\n",
    "        new_spin_array = [spin for spin in current_spin_array] # make a copy of the current spin array\n",
    "        new_spin_array[flipping_loc] *= -1 # flip the spin at desired location\n",
    "        new_spin_array_energy = get_array_energy(new_spin_array, J, h) # calculate the energy of the new spin array\n",
    "        new_spin_array_magnetization = magnetization_per_spin(new_spin_array)\n",
    "        \n",
    "        exponential = np.exp(-(1/(k_B*T[iteration]))*(new_spin_array_energy - current_energy ))\n",
    "        \n",
    "        if r < min(1, exponential):\n",
    "            # accept the new configuration\n",
    "            current_spin_array = new_spin_array\n",
    "            current_energy = new_spin_array_energy\n",
    "            current_magnetization = new_spin_array_magnetization\n",
    "            all_configurations.append(np.array(current_spin_array))\n",
    "            all_magnetizations.append(magnetization_per_spin(current_spin_array))\n",
    "            print(f\"Iteration {iteration+1}: {current_spin_array}, energy: {current_energy} , magnetization: {current_magnetization}\")\n",
    "            \n",
    "        else:\n",
    "             # keep the old configuration\n",
    "            new_spin_array[flipping_loc] *= -1 # flip the spin to re-obtain the old configuration\n",
    "            current_spin_array = new_spin_array\n",
    "            current_magnetization = new_spin_array_magnetization\n",
    "            all_configurations.append(np.array(current_spin_array))\n",
    "            all_magnetizations.append(magnetization_per_spin(current_spin_array))\n",
    "            print(f\"Iteration {iteration+1}: {current_spin_array}, energy: {current_energy} , magnetization: {current_magnetization}\")\n",
    "        \n",
    "        iteration += 1\n",
    "    \n",
    "    return all_configurations, all_magnetizations    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corresponding-kuwait",
   "metadata": {},
   "outputs": [],
   "source": [
    "def magnetic_field(time, variable): # variable can be any time-dependent magnetic fied\n",
    "    h = 4\n",
    "    if variable == True:\n",
    "        h1 = [4 for t in range(1,int(time/2))]\n",
    "        h2 = [ 0 for t in range(int(time/2), int(time+1))]\n",
    "        fields = h1 + h2\n",
    "        return fields\n",
    "    else:\n",
    "        fields = [h for i in range(0,time)]\n",
    "        return fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opening-practice",
   "metadata": {},
   "outputs": [],
   "source": [
    "def temperature(time, T, variable): # variable can be any time-dependent temperature\n",
    "    if variable == True:\n",
    "        temperatures1 = [T for t in range(1,int(time/2))] # half of the time T\n",
    "        temperatures2 = [ T*190 for t in range(int(time/2), int(time+1))] # hlaf of the time 100*T\n",
    "        temperatures = temperatures1 + temperatures2\n",
    "        #temperatures = np.array(list(range(0, time, 1)))\n",
    "        #return temperatures*0.1\n",
    "        #print(temperatures)\n",
    "        return temperatures\n",
    "    else:\n",
    "        temperatures = [T for i in range(0,time)]\n",
    "        return temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "irish-miniature",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_spins = 50\n",
    "N_up = 25\n",
    "J = 1\n",
    "k_B = 1\n",
    "max_iter = 500\n",
    "#h = magnetic_field(max_iter, False)\n",
    "h = 4\n",
    "T = temperature(max_iter, 0.1, True) # if False, temperature will be constant, otherwise it will be varaible in time\n",
    "\n",
    "#test_spin_array1 = [1, -1, 1, -1, 1, -1, 1, -1, 1, -1]\n",
    "#test_spin_array2 = [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n",
    "\n",
    "spin_array = get_spin_array(N_spins, N_up, N_spins - N_up)\n",
    "spin_array_energy = get_array_energy(spin_array, J, h)\n",
    "spin_array_magn = magnetization_per_spin(spin_array)\n",
    "print(f\"Array of {N_spins} spins, {N_up} are up, {N_spins - N_up} are down: {spin_array}, energy: {spin_array_energy}, magnetization: {spin_array_magn}\")\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "equilibrium_configuration = metropolis_monte_carlo(spin_array, T, max_iter, J, h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solved-spanking",
   "metadata": {},
   "source": [
    "Let us make an animation of Monte-Carlo simulation. In first place we need a function which plots the spin array produced at a given iteration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-writing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_array(spin_array):\n",
    "    spin_array = np.array(spin_array)\n",
    "    y = [0 for i in range(0, len(spin_array) + 1)] # all spin are alligned along x-axis\n",
    "    for index, spin in enumerate(spin_array):\n",
    "        if spin == 1:\n",
    "            plt.scatter(index, 0, color='m', marker='s', label='up', edgecolors='k')\n",
    "        else:\n",
    "            plt.scatter(index, 0, color='y', marker='s', label='down', edgecolors='k')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unavailable-difficulty",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.animation as animation\n",
    "\n",
    "metadata = dict(title = '1D_Ising_model')\n",
    "writer = PillowWriter(fps = 10, metadata = metadata)\n",
    "\n",
    "spin_positions = np.array(list(range(0, N_spins, 1)))\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8,4))\n",
    "l, = plt.plot([], [])\n",
    "time_text = ax.text(0.05, 0.9, '', fontsize=12, transform=ax.transAxes, bbox=dict(facecolor='white', edgecolor='black'))\n",
    "temp_text = ax.text(0.3, 0.9, '', fontsize=12, transform=ax.transAxes, bbox=dict(facecolor='white', edgecolor='black'))\n",
    "field_text = ax.text(0.61, 0.9, '', fontsize=12, transform=ax.transAxes, bbox=dict(facecolor='white', edgecolor='black'))\n",
    "N_spin_text = ax.text(0.05, 0.7, '', fontsize=12, transform=ax.transAxes, bbox=dict(facecolor='white', edgecolor='black'))\n",
    "#N_up_text = ax.text(0.3, 0.7, '', fontsize=12, transform=ax.transAxes, bbox=dict(facecolor='white', edgecolor='black'))\n",
    "#N_down_text = ax.text(0.61, 0.7, '', fontsize=12, transform=ax.transAxes, bbox=dict(facecolor='white', edgecolor='black'))\n",
    "magn_text = ax.text(0.3, 0.7, '', fontsize=12, transform=ax.transAxes, bbox=dict(facecolor='white', edgecolor='black'))\n",
    "plt.legend(loc='lower right', ncol=2)\n",
    "plt.ylim(-1, 1.5)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.xlabel('Spin locations')\n",
    "plt.title('1-dimensional Ising model')\n",
    "\n",
    "def animate(iteration):\n",
    "    time_text.set_text('Iteration={:.2f}'.format(iteration))\n",
    "    temp_text.set_text('Temperature={:.2f} K'.format(T[iteration]))\n",
    "    field_text.set_text('Field={:.2f}'.format(h))\n",
    "    N_spin_text.set_text('Spins={:.2f}'.format(N_spins))\n",
    "    #N_up_text.set_text('Spins up={:.2f}'.format(list(equilibrium_configuration[0][iteration]).count(1)))\n",
    "    #N_down_text.set_text('Spins down={:.2f}'.format(list(equilibrium_configuration[0][iteration]).count(-1)))\n",
    "    magn_text.set_text('m={:.2f}'.format(equilibrium_configuration[1][iteration]))\n",
    "    l.set_data(spin_positions, plot_array(equilibrium_configuration[0][iteration]))\n",
    "\n",
    "\n",
    "ani = animation.FuncAnimation(fig, animate, frames=len(equilibrium_configuration[0]), interval=100)\n",
    "ani.save(r'C:Ising_1D.gif', writer='pillow')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focused-nashville",
   "metadata": {},
   "source": [
    "Here we make an animation of the evolution of magnetization per spin $m = \\langle s_i\\rangle$. Then we can play with control parameters i.e. temperature and magnetic field. We can verify that, if there is no magnetic field turned on, the one-dimensional system experiences no spontaneous magnetization even if we are under the critical temperature. This is a typical carachteristic of 1D Ising model which is explained by Wagner-Mermin theorem: continuous symmetries cannot be spontaneously broken at finite temperatures, in finite systems with low-range interactions and a number of dimensions smaller or equal than 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "talented-logging",
   "metadata": {},
   "outputs": [],
   "source": [
    "# magnetization\n",
    "\n",
    "metadata = dict(title = 'Magnetization')\n",
    "writer = PillowWriter(fps = 10, metadata = metadata)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8,4))\n",
    "l, = plt.plot([], [], 'b-')\n",
    "time_text = ax.text(0.05, 0.9, '', fontsize=12, transform=ax.transAxes, bbox=dict(facecolor='white', edgecolor='black'))\n",
    "temp_text = ax.text(0.3, 0.9, '', fontsize=12, transform=ax.transAxes, bbox=dict(facecolor='white', edgecolor='black'))\n",
    "field_text = ax.text(0.61, 0.9, '', fontsize=12, transform=ax.transAxes, bbox=dict(facecolor='white', edgecolor='black'))\n",
    "plt.xlim(0, len(equilibrium_configuration[0]))\n",
    "plt.ylim(-1.5, 2)\n",
    "plt.axhline(y = 0, color = 'k', linestyle = '--') \n",
    "plt.axhline(y = 1, color = 'r', linestyle = '-') \n",
    "plt.axhline(y = -1, color = 'r', linestyle = '-') \n",
    "plt.grid(True)\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Magnetization per spin')\n",
    "\n",
    "xvals = []\n",
    "yvals = []\n",
    "\n",
    "with writer.saving(fig, \"Magnetization.gif\", 100):\n",
    "    magnetizations = equilibrium_configuration[1] # \"n magnetizations\" list is n+1 elements long\n",
    "    for iteration, magnetization in  enumerate(list(magnetizations)):\n",
    "        xvals.append(iteration)\n",
    "        yvals.append(magnetization)\n",
    "        \n",
    "        time_text.set_text('Iteration={:.2f}'.format(iteration))\n",
    "        temp_text.set_text('Temperature={:.2f} K'.format(T[iteration]))\n",
    "        field_text.set_text('Field={:.2f}'.format(h))\n",
    "        l.set_data(xvals, yvals)\n",
    "        \n",
    "        writer.grab_frame()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "second-groove",
   "metadata": {},
   "source": [
    "Let us now study the correlation length at various distances. Thus we choose one spin and calculate the correlation with all the others at different temperatures. We want to notice that the maximum correlation is achieved at the critical temeprature. In particular, in this first phase, we want to study equilibrium equal-time spatial correlations. Hence we first need to find the equilibrium state and then we study the correlation. In first place we need a function which receives multiple spin arrays which have been produced at a given temperature and calculates the correlation between spin at location zero and all the others.\n",
    "\n",
    "## Attention\n",
    "\n",
    "This part of the code is not working currently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coral-smell",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlations(matrix_of_configurations):\n",
    "    \n",
    "    col_max = len(list(matrix_of_configurations[0]))\n",
    "    number_of_iterations = len(matrix_of_configurations)\n",
    "    matrix = np.array(matrix_of_configurations)\n",
    "    \n",
    "    average_spins = []\n",
    "    for col in range(col_max-1):\n",
    "        #average_spin = np.mean(matrix[:,col])\n",
    "        average_spin = sum(matrix[:,col])/number_of_iterations\n",
    "        average_spins.append(average_spin)\n",
    "    \n",
    "    #print(f\"Av spins = {average_spins}\")\n",
    "    \n",
    "    average_products = []\n",
    "    spin_spin_products = []\n",
    "    \n",
    "    for col in range(col_max-1):        \n",
    "        for configuration in matrix_of_configurations:\n",
    "            spin_spin_prod = configuration[0]*configuration[col]\n",
    "            spin_spin_products.append(spin_spin_prod)\n",
    "        average_products.append(sum(spin_spin_products)/number_of_iterations)\n",
    "        #print(f\"Spin-spin products:{spin_spin_products}\")\n",
    "        spin_spin_products.clear()\n",
    "        \n",
    "        #average_product = np.mean(matrix[:,0]@matrix[:,col])\n",
    "        #average_products.append(average_product)\n",
    "    \n",
    "    print(\"\")\n",
    "    print(f\"Av products = {average_products}\")\n",
    "    \n",
    "    correlations = []\n",
    "    first_av_spin = average_spins[0] # average value of the spin at which we are pointing\n",
    "    for av_prod, av_spin in zip(average_products, average_spins):\n",
    "        correlations.append(av_prod - (first_av_spin*av_spin))\n",
    "        \n",
    "    return correlations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contemporary-cooperation",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_spins = 100\n",
    "N_up = 50\n",
    "J = 1\n",
    "k_B = 1\n",
    "max_iter = 200\n",
    "#h = magnetic_field(max_iter, False)\n",
    "h = 4\n",
    "\n",
    "# Set three different constant temperatures\n",
    "\n",
    "temperatures = [temperature(max_iter, i, False) for i in [0.1]]\n",
    "\n",
    "spin_array = get_spin_array(N_spins, N_up, N_spins - N_up)\n",
    "spin_array_energy = get_array_energy(spin_array, J, h)\n",
    "spin_array_magn = magnetization_per_spin(spin_array)\n",
    "print(f\"Array of {N_spins} spins, {N_up} are up, {N_spins - N_up} are down: {spin_array}, energy: {spin_array_energy}, magnetization: {spin_array_magn}\")\n",
    "\n",
    "fig = plt.figure(figsize=(8,4))\n",
    "distances = np.array(list(range(0, N_spins-1, 1)))\n",
    "plt.grid(True)\n",
    "plt.xlabel('Spin locations')\n",
    "plt.ylabel('Correlation')\n",
    "plt.title('Correlations at three different temperatures')\n",
    "\n",
    "for temp in temperatures:\n",
    "    \n",
    "    equilibrium_configuration = metropolis_monte_carlo(spin_array, temp, max_iter, J, h)\n",
    "    correlations = get_correlations(equilibrium_configuration[0])\n",
    "    print(\"\")\n",
    "    print(f\"Correlations = {correlations}\")\n",
    "    plt.plot(distances, correlations, 'o', label=f'{temp[0]}')\n",
    "    plt.legend(loc='upper right')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immediate-venezuela",
   "metadata": {},
   "source": [
    "# 2-D Ising model\n",
    "\n",
    "Here we have to take into account the presence of spins distributed over a NxN grid. Thus, the spin-spin interaction is verified for all the first neighbours. We can recycle the approach used for the 1-D Ising model by appropriately modifying the functions.\n",
    "in this case, the energetic contribution of one spin is:\n",
    "\n",
    "$$E_{ij} = -J[s_{ij}s_{i-1,j} + s_{ij}s_{i+1,j} + s_{ij}s_{i,j-1} + s_{ij}s_{i,j+1}] - hs_{ij}$$\n",
    "\n",
    "Then, the energy of the entire lattice is:\n",
    "\n",
    "$$H = -J\\sum_{i=0}^{N-1}\\sum_{\\langle i,j\\rangle}s_{i}s_{i+1} - h\\sum_{i,j}s_{i,j}$$\n",
    "\n",
    "Where the notation $\\langle i,j\\rangle$ is indicatig the nearest neighbours of spin $s_{ij}$.\n",
    "\n",
    "In first place we need a function which generates a random spin grid. This function receives the number of rows and columns and the number of up spins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colored-fraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spin_grid(N_rows, N_cols, N_up):\n",
    "    # N_rows is the number of rows\n",
    "    # N_cols is the number of columns i.e. the number of spins per row\n",
    "    grid = [] # will become a list of lists\n",
    "    N_down = N_cols - N_up # number of down spins in one row\n",
    "    for spin_array in range(N_rows):        \n",
    "        #for spin in range(N_cols):\n",
    "        list_of_spin_down = [-1 for i in range(N_down)]\n",
    "        list_of_spin_up = [1 for i in range(N_up)]\n",
    "        spin_array = sample(list_of_spin_down + list_of_spin_up, len(list_of_spin_down + list_of_spin_up))\n",
    "        grid.append(spin_array)\n",
    "    return np.array(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "color-grove",
   "metadata": {},
   "source": [
    "Now we create another function which displays the grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advance-privilege",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grid(grid):\n",
    "    # first generate the vertical positions\n",
    "    ys = np.array(list(range(0, len(grid), 1)))\n",
    "    for y, row in zip(reversed(ys), grid):\n",
    "        for index, spin in enumerate(row):\n",
    "            if spin == 1:\n",
    "                #plt.scatter(index, y, color='m', marker='s', label='up') # edgecolors='k'\n",
    "                plt.plot(index, y, color='m', marker='s', label='up') # edgecolors='k'\n",
    "            else:\n",
    "                #plt.scatter(index, y, color='y', marker='s', label='down')\n",
    "                plt.plot(index, y, color='y', marker='s', label='down')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banner-remainder",
   "metadata": {},
   "source": [
    "Now we need a function which calculates the grid energy. Here we are not imposing periodic boundary conditions, thus we have to take into account that spins at the edges of the grides will have less nearest neighbours. For example, spin $s_{00}$ will have energy: $E_{00} = -J[s_{00}\\cdot s_{01} + s_{00}\\cdot s_{10}] - hs_{00}$. Hence, for each spin we have to identify the coordinates of the nearest neighbour. If such coordinates are found outside the grid, then it means that there is no neighbour in that direction and the energy contribtuion for that spin is zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprised-duplicate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grid_energy(grid, J, h):\n",
    "    \n",
    "    H1 = 0\n",
    "    H2 = 0\n",
    "    for row_index, row in enumerate(grid):\n",
    "        for spin_index, spin in enumerate(row):\n",
    "            # here we must verify that nearest neighbours are inside the grid\n",
    "            \n",
    "            # let us first calculate the contribution at the right of the current spin\n",
    "            if (spin_index+1) < len(row):\n",
    "                E_right = spin*row[spin_index+1]\n",
    "            else:\n",
    "                E_right = 0\n",
    "            \n",
    "            # let us now calcualte the contribution at the left of the current spin\n",
    "            if (spin_index-1) >= 0:\n",
    "                E_left = spin*row[spin_index-1]\n",
    "            else:\n",
    "                E_left = 0\n",
    "                \n",
    "            # let us now calculate the contribution at the top of the current spin\n",
    "            if row_index-1 >= 0:\n",
    "                E_top = spin*grid[row_index-1][spin_index]\n",
    "            else:\n",
    "                E_top = 0\n",
    "                \n",
    "            # let us now calculate the contribution at the bottom of the current spin\n",
    "            if row_index+1 < len(grid):\n",
    "                E_bottom = spin*grid[row_index+1][spin_index]\n",
    "            else:\n",
    "                E_bottom = 0\n",
    "                \n",
    "            H1 += E_right + E_left + E_top + E_bottom\n",
    "            \n",
    "            #print(f\"H1: {H1}\")\n",
    "            \n",
    "    H2 = np.sum(grid)\n",
    "    #print(f\"H2: {H2}\")\n",
    "    \n",
    "    return -J*H1 - h*H2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-dream",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_magnetization(grid):\n",
    "    return np.mean(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "horizontal-flour",
   "metadata": {},
   "outputs": [],
   "source": [
    "def magnetic_field(time, variable): # variable can be any time-dependent magnetic fied\n",
    "    h = 4\n",
    "    if variable == True:\n",
    "        h1 = [4 for t in range(1,int(time/2))]\n",
    "        h2 = [ 0 for t in range(int(time/2), int(time+1))]\n",
    "        fields = h1 + h2\n",
    "        return fields\n",
    "    else:\n",
    "        fields = [h for i in range(0,time)]\n",
    "        return fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "golden-march",
   "metadata": {},
   "outputs": [],
   "source": [
    "def temperature(time, T, variable): # variable can be any time-dependent temperature\n",
    "    if variable == True:\n",
    "        temperatures1 = [T for t in range(1,int(time/2))] # half of the time T\n",
    "        temperatures2 = [ T*190 for t in range(int(time/2), int(time+1))] # hlaf of the time 100*T\n",
    "        temperatures = temperatures1 + temperatures2\n",
    "        #temperatures = np.array(list(range(0, time, 1)))\n",
    "        #return temperatures*0.1\n",
    "        #print(temperatures)\n",
    "        return temperatures\n",
    "    else:\n",
    "        temperatures = [T for i in range(0,time)]\n",
    "        return temperatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resident-chance",
   "metadata": {},
   "source": [
    "It is now time to implement Metropolis Monte-Carlo algorithm for a grid of spins rather than for a one-dimensional array. The procedure is exactly the same, we just have to adapt the previous function to the 2-dimensional case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conceptual-horror",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metropolis_monte_carlo(grid, J, T, h, max_iter):\n",
    "    \n",
    "    \n",
    "    all_configurations = [] # list with all Monte-Carlo configurations (i.e. a list containing matrices), needed for animation\n",
    "    all_configurations.append(grid)\n",
    "    \n",
    "    all_magnetizations = [] # list with all magnetization densities, needed for animation\n",
    "    all_magnetizations.append(get_magnetization(grid))\n",
    "    \n",
    "    # here we start Monte-Carlo method\n",
    "    \n",
    "    # Let us define the initial configuration, calculate its energy and magnetization\n",
    "    current_grid = grid\n",
    "    current_energy = get_grid_energy(current_grid, J, h)\n",
    "    current_magnetization = get_magnetization(current_grid)\n",
    "    \n",
    "    r = np.random.random() # sort a float in range (0,1), which is our accepatance level\n",
    "    \n",
    "    k_B = 1\n",
    "    iteration = 0\n",
    "    while iteration < max_iter:\n",
    "        \n",
    "        # generate a random position on the grid (i.e. a tuple) where we can flip the spin\n",
    "        flipping_coordinates = np.array([random.randint(0, len(grid[0])-1), random.randint(0, len(grid)-1)])\n",
    "        new_grid = np.array([row for row in current_grid]) # make a copy of the current spin grid\n",
    "        new_grid[flipping_coordinates[0]][flipping_coordinates[1]] *= -1 # flip the spin at desired location\n",
    "        new_grid_energy = get_grid_energy(new_grid, J, h) # calculate the energy of the new spin grid\n",
    "        new_grid_magnetization = get_magnetization(new_grid) # calculate the new magnetization density\n",
    "        \n",
    "        exponential = np.exp(-(1/(k_B*T[iteration]))*(new_grid_energy - current_energy ))\n",
    "        \n",
    "        if r < min(1, exponential):\n",
    "            # accept the new configuration\n",
    "            current_grid = new_grid\n",
    "            current_energy = new_grid_energy\n",
    "            current_magnetization = new_grid_magnetization\n",
    "            all_configurations.append(np.array(current_grid))\n",
    "            all_magnetizations.append(get_magnetization(current_grid))\n",
    "            #print(f\"Iteration {iteration+1}: {current_grid}, energy: {current_energy} , magnetization: {current_magnetization}\")\n",
    "            \n",
    "        else:\n",
    "             # keep the old configuration\n",
    "            new_grid[flipping_coordinates[0]][flipping_coordinates[1]] *= -1 # flip the spin to re-obtain the old configuration\n",
    "            current_grid = new_grid\n",
    "            current_magnetization = new_grid_magnetization\n",
    "            all_configurations.append(np.array(current_grid))\n",
    "            all_magnetizations.append(get_magnetization(current_grid))\n",
    "            #print(f\"Iteration {iteration+1}: {current_grid}, energy: {current_energy} , magnetization: {current_magnetization}\")\n",
    "        \n",
    "        iteration += 1\n",
    "    \n",
    "    return all_configurations, all_magnetizations    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selective-moment",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_rows = 10\n",
    "N_cols = 10\n",
    "total_spins = N_rows*N_cols\n",
    "N_up = 5 # number of spin up per row\n",
    "total_up = N_up*N_rows #total number of spin up\n",
    "\n",
    "max_iter = 100\n",
    "h = 2\n",
    "J = 1\n",
    "T = temperature(max_iter+1, 0.1, False)\n",
    "\n",
    "initial_grid = get_spin_grid(N_rows, N_cols, N_up)\n",
    "initial_energy = get_grid_energy(initial_grid, J, h)\n",
    "initial_magnetization = get_magnetization(initial_grid)\n",
    "print(f\"Grid of {total_spins} spins, {total_up} are up, {total_spins - total_up} are down\")\n",
    "print(f\"Energy: {initial_energy}, magnetization: {initial_magnetization}\")\n",
    "plot_grid(initial_grid)\n",
    "print(\"\")\n",
    "\n",
    "equilibrium_configuration = metropolis_monte_carlo(initial_grid, J, T, h, max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regional-mainland",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_grid(equilibrium_configuration[0][max_iter-1])\n",
    "print(f\"magnetization per spin: {equilibrium_configuration[1][max_iter-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dirty-enforcement",
   "metadata": {},
   "source": [
    "## Attention:  \n",
    "The animations are saved in mp4 format, thus ffmpeg is needed on your computer. If you are unable to install it, run the instructions on Google Colab and everything will work fine. Alternatively you can use another writer (like the one used in previous sections) and produce gif animations (though it will require a lot of time and the relust will be very low-quality)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "encouraging-telephone",
   "metadata": {},
   "source": [
    "Let us start from the animation of magnetization density since it is going to need less time than the spin grid animation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expected-allowance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# magnetization\n",
    "from matplotlib.animation import FFMpegWriter, writers\n",
    "\n",
    "metadata = dict(title = 'Magnetization_density')\n",
    "Writer = writers['ffmpeg']\n",
    "writer = Writer(fps=20, metadata={'artist': 'Me'}, bitrate=1000)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8,4))\n",
    "l, = plt.plot([], [], 'b-')\n",
    "time_text = ax.text(0.05, 0.9, '', fontsize=12, transform=ax.transAxes, bbox=dict(facecolor='white', edgecolor='black'))\n",
    "temp_text = ax.text(0.3, 0.9, '', fontsize=12, transform=ax.transAxes, bbox=dict(facecolor='white', edgecolor='black'))\n",
    "field_text = ax.text(0.61, 0.9, '', fontsize=12, transform=ax.transAxes, bbox=dict(facecolor='white', edgecolor='black'))\n",
    "plt.xlim(0, len(equilibrium_configuration[0]))\n",
    "plt.ylim(-1.5, 2)\n",
    "plt.axhline(y = 0, color = 'k', linestyle = '--')\n",
    "plt.axhline(y = 1, color = 'r', linestyle = '-')\n",
    "plt.axhline(y = -1, color = 'r', linestyle = '-')\n",
    "plt.grid(True)\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Magnetization per spin')\n",
    "\n",
    "xvals = []\n",
    "yvals = []\n",
    "\n",
    "with writer.saving(fig, \"Magnetization.mp4\", 100):\n",
    "    magnetizations = equilibrium_configuration[1] # \"n magnetizations\" list is n+1 elements long\n",
    "    for iteration, magnetization in  enumerate(list(magnetizations)):\n",
    "        xvals.append(iteration)\n",
    "        yvals.append(magnetization)\n",
    "\n",
    "        time_text.set_text('Iteration={:.2f}'.format(iteration))\n",
    "        temp_text.set_text('Temperature={:.2f} K'.format(T[iteration]))\n",
    "        field_text.set_text('Field={:.2f}'.format(h))\n",
    "        l.set_data(xvals, yvals)\n",
    "        plt.close()\n",
    "\n",
    "        writer.grab_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floral-slope",
   "metadata": {},
   "source": [
    "Here we make an animation of the 2-D spin grid. Unfortunately, for large spin systems (even 10x10), the animation takes too long to be accomplished. The solution to this issue is to sample the frames at certain intervals one from the others. In this way the animation does not include exactly all the iterations but it will look much more fluid and, most importantly, the program will be able to complete it (2 hours for a 100x100 grid, 10k iterations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thrown-wilson",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.animation import FFMpegWriter, writers\n",
    "\n",
    "metadata = dict(title = '2D_Ising_model')\n",
    "\n",
    "spin_positions = np.array(list(range(0, N_cols, 1)))\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8,8))\n",
    "l, = plt.plot([], [])\n",
    "#time_text = ax.text(0.05, N_rows+0.5, '', fontsize=12, transform=ax.transAxes, bbox=dict(facecolor='white', edgecolor='black'))\n",
    "'''temp_text = ax.text(0.3, 0.9, '', fontsize=12, transform=ax.transAxes, bbox=dict(facecolor='white', edgecolor='black'))\n",
    "field_text = ax.text(0.61, 0.9, '', fontsize=12, transform=ax.transAxes, bbox=dict(facecolor='white', edgecolor='black'))\n",
    "N_spin_text = ax.text(0.05, 0.7, '', fontsize=12, transform=ax.transAxes, bbox=dict(facecolor='white', edgecolor='black'))\n",
    "#N_up_text = ax.text(0.3, 0.7, '', fontsize=12, transform=ax.transAxes, bbox=dict(facecolor='white', edgecolor='black'))\n",
    "#N_down_text = ax.text(0.61, 0.7, '', fontsize=12, transform=ax.transAxes, bbox=dict(facecolor='white', edgecolor='black'))\n",
    "magn_text = ax.text(0.3, 0.7, '', fontsize=12, transform=ax.transAxes, bbox=dict(facecolor='white', edgecolor='black'))'''\n",
    "plt.legend(loc='lower right', ncol=2)\n",
    "plt.xlim(-0.5, N_cols)\n",
    "plt.ylim(-0.5, N_rows)\n",
    "plt.grid(True)\n",
    "\n",
    "#plt.xlabel('Spin locations')\n",
    "plt.title('2-dimensional Ising model')\n",
    "\n",
    "def animate(iteration):\n",
    "    scale = 100\n",
    "    #time_text.set_text('Iteration={:.2f}'.format(iteration))\n",
    "    '''\n",
    "    temp_text.set_text('Temperature={:.2f} K'.format(T[iteration]))\n",
    "    field_text.set_text('Field={:.2f}'.format(h))\n",
    "    N_spin_text.set_text('Spins={:.2f}'.format(total_spins))\n",
    "    #N_up_text.set_text('Spins up={:.2f}'.format(list(equilibrium_configuration[0][iteration]).count(1)))\n",
    "    #N_down_text.set_text('Spins down={:.2f}'.format(list(equilibrium_configuration[0][iteration]).count(-1)))\n",
    "    magn_text.set_text('m={:.2f}'.format(equilibrium_configuration[1][iteration]))'''\n",
    "    # select only one frame every N iterations, otherwise it takes too long and the program fails\n",
    "    l.set_data(spin_positions, plot_grid(equilibrium_configuration[0][iteration*scale]))\n",
    "\n",
    "ani = animation.FuncAnimation(fig, animate, frames=len(equilibrium_configuration[0]), interval=5)\n",
    "\n",
    "Writer = writers['ffmpeg']\n",
    "writer = Writer(fps=20, metadata={'artist': 'Me'}, bitrate=1000)\n",
    "\n",
    "ani.save('Ising_2D.mp4', writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greenhouse-train",
   "metadata": {},
   "source": [
    "This is the end of the Ising model. Possible improvements could be:\n",
    "\n",
    "1)review the code about the correlation function <br>\n",
    "2)evaluate specific heat and other observables"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
